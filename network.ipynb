{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = Namespace(\n",
    "    train_file='harry.txt',\n",
    "    seq_size=32,\n",
    "    batch_size=16,\n",
    "    embedding_size=64,\n",
    "    lstm_size=64,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['I', 'am'],\n",
    "    predict_top_k=5,\n",
    "    checkpoint_path='checkpoint',\n",
    ")\n",
    "\n",
    "\n",
    "def get_data_from_file(train_file, batch_size, seq_size):\n",
    "    with open(train_file, 'r') as f:\n",
    "        text = f.read()\n",
    "    text = text.split()\n",
    "\n",
    "    word_counts = Counter(text)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "    n_vocab = len(int_to_vocab)\n",
    "\n",
    "    print('Vocabulary size', n_vocab)\n",
    "\n",
    "    int_text = [vocab_to_int[w] for w in text]\n",
    "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "    out_text = np.zeros_like(in_text)\n",
    "    out_text[:-1] = in_text[1:]\n",
    "    out_text[-1] = in_text[0]\n",
    "    in_text = np.reshape(in_text, (batch_size, -1))\n",
    "    out_text = np.reshape(out_text, (batch_size, -1))\n",
    "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))\n",
    "\n",
    "\n",
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    return criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_file(\n",
    "        flags.train_file, flags.batch_size, flags.seq_size)\n",
    "\n",
    "    net = RNNModule(n_vocab, flags.seq_size,\n",
    "                    flags.embedding_size, flags.lstm_size)\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
    "\n",
    "    iteration = 0\n",
    "    for e in range(20):\n",
    "        batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
    "        state_h, state_c = net.zero_state(flags.batch_size)\n",
    "        \n",
    "        # Transfer data to GPU\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        for x, y in batches:\n",
    "            iteration += 1\n",
    "            \n",
    "            # Tell it we are in training mode\n",
    "            net.train()\n",
    "\n",
    "            # Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Transfer data to GPU\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "\n",
    "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # Perform back-propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            _ = torch.nn.utils.clip_grad_norm_(net.parameters(), flags.gradients_norm)\n",
    "\n",
    "            # Update the network's parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(e, 20),\n",
    "                      'Iteration: {}'.format(iteration),\n",
    "                      'Loss: {}'.format(loss_value))\n",
    "\n",
    "            if iteration % 1000 == 0:\n",
    "                predict(device, net, flags.initial_words, n_vocab,\n",
    "                        vocab_to_int, int_to_vocab, top_k=5)\n",
    "                torch.save(net.state_dict(),\n",
    "                           'model-{}.pth'.format(iteration))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9d3e400e60ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Transfer data to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in_text' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'choice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-eee1fec6efa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'choice' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 11897\n",
      "Epoch: 0/20 Iteration: 100 Loss: 7.290021896362305\n",
      "Epoch: 1/20 Iteration: 200 Loss: 6.573996543884277\n",
      "Epoch: 1/20 Iteration: 300 Loss: 6.133031368255615\n",
      "Epoch: 2/20 Iteration: 400 Loss: 5.5774641036987305\n",
      "Epoch: 3/20 Iteration: 500 Loss: 5.312753200531006\n",
      "Epoch: 3/20 Iteration: 600 Loss: 4.89790153503418\n",
      "Epoch: 4/20 Iteration: 700 Loss: 4.570477485656738\n",
      "Epoch: 5/20 Iteration: 800 Loss: 4.3993306159973145\n",
      "Epoch: 5/20 Iteration: 900 Loss: 4.000272274017334\n",
      "Epoch: 6/20 Iteration: 1000 Loss: 4.049887657165527\n",
      "I am Fred,\" Harry tried about the Quidditch and floor. The moment of his head torn down his head hurt. Potter. We want a very good term between lessons who had a bit o' you in a little package. Try because of a cat nor to get rid but they had been a very sunny grounds. Harry was the way in front steps and he said, and Ron were sure they could get up next morning the dark cupboard, I was so worried about the other side, in front when the dark silver beard. Dudley of course, Harry and Hermione Granger, us in my eyes because they could be able in the door and Piers Polkiss, stared on his head. As they waited, the way into his head suspended in his hands together. There were the other choice... she was almost flew, up the way from view; Harry tried into it was going on his broomstick was the first day at a moment than ours, \" said Hagrid. Harry had never had never had never believed his wand and he wasn't sure they knew the way into the way and the door untouched. He didn't know what was very noisy that evening. Hagrid had to keep Harry in a little way for breath, in a few seconds before the first time -- he was the way of his eyes when it wasn't going on? Dudley was still alive music stores, look at Harry's sweater. \"I will die, had never return to his eyes off their kind.... A Guide for dinner, from Harry. \"You have to do it will have a bit late for spotting Hermione was standing so the dark corridors. UP a large wooden flute. Snape had been so glad to Harry told Harry and Ron was going out the other and Hermione was\n",
      "Epoch: 7/20 Iteration: 1100 Loss: 3.6628029346466064\n",
      "Epoch: 7/20 Iteration: 1200 Loss: 3.787759304046631\n",
      "Epoch: 8/20 Iteration: 1300 Loss: 3.6611692905426025\n",
      "Epoch: 9/20 Iteration: 1400 Loss: 3.3291945457458496\n",
      "Epoch: 9/20 Iteration: 1500 Loss: 3.327741861343384\n",
      "Epoch: 10/20 Iteration: 1600 Loss: 3.3393728733062744\n",
      "Epoch: 11/20 Iteration: 1700 Loss: 3.1491963863372803\n",
      "Epoch: 11/20 Iteration: 1800 Loss: 3.06103253364563\n",
      "Epoch: 12/20 Iteration: 1900 Loss: 3.125342607498169\n",
      "Epoch: 13/20 Iteration: 2000 Loss: 2.8471555709838867\n",
      "I am Fred,\" Harry tried about the Quidditch and floor. The moment of his head torn down his head hurt. Potter. We want a very good term between lessons who had a bit o' you in a little package. Try because of a cat nor to get rid but they had been a very sunny grounds. Harry was the way in front steps and he said, and Ron were sure they could get up next morning the dark cupboard, I was so worried about the other side, in front when the dark silver beard. Dudley of course, Harry and Hermione Granger, us in my eyes because they could be able in the door and Piers Polkiss, stared on his head. As they waited, the way into his head suspended in his hands together. There were the other choice... she was almost flew, up the way from view; Harry tried into it was going on his broomstick was the first day at a moment than ours, \" said Hagrid. Harry had never had never had never believed his wand and he wasn't sure they knew the way into the way and the door untouched. He didn't know what was very noisy that evening. Hagrid had to keep Harry in a little way for breath, in a few seconds before the first time -- he was the way of his eyes when it wasn't going on? Dudley was still alive music stores, look at Harry's sweater. \"I will die, had never return to his eyes off their kind.... A Guide for dinner, from Harry. \"You have to do it will have a bit late for spotting Hermione was standing so the dark corridors. UP a large wooden flute. Snape had been so glad to Harry told Harry and Ron was going out the other and Hermione was still out on earth like to the first years. The rest with Harry's mind. As Hagrid's sort on Snape's robes on, I hear the boy came striding down to its beak, -- Beaters.\" Harry and Ron had to the first time in that fateful people in a magnificent mirror, as high, made his head under a small crowd. look on the night -- he said smoothly. A look. Was in here over here! A sudden hush, in one of what he could hardly speak. He didn't have done yer things friendly. of him. \"See?\" came I've just knew about it, you'd\n",
      "Epoch: 13/20 Iteration: 2100 Loss: 2.556102991104126\n",
      "Epoch: 14/20 Iteration: 2200 Loss: 2.7477047443389893\n",
      "Epoch: 15/20 Iteration: 2300 Loss: 2.8476791381835938\n",
      "Epoch: 15/20 Iteration: 2400 Loss: 2.566361665725708\n",
      "Epoch: 16/20 Iteration: 2500 Loss: 2.658700466156006\n",
      "Epoch: 16/20 Iteration: 2600 Loss: 2.7591006755828857\n",
      "Epoch: 17/20 Iteration: 2700 Loss: 2.51828670501709\n",
      "Epoch: 18/20 Iteration: 2800 Loss: 2.3372676372528076\n",
      "Epoch: 18/20 Iteration: 2900 Loss: 2.5176098346710205\n",
      "Epoch: 19/20 Iteration: 3000 Loss: 2.4849250316619873\n",
      "I am Fred,\" Harry tried about the Quidditch and floor. The moment of his head torn down his head hurt. Potter. We want a very good term between lessons who had a bit o' you in a little package. Try because of a cat nor to get rid but they had been a very sunny grounds. Harry was the way in front steps and he said, and Ron were sure they could get up next morning the dark cupboard, I was so worried about the other side, in front when the dark silver beard. Dudley of course, Harry and Hermione Granger, us in my eyes because they could be able in the door and Piers Polkiss, stared on his head. As they waited, the way into his head suspended in his hands together. There were the other choice... she was almost flew, up the way from view; Harry tried into it was going on his broomstick was the first day at a moment than ours, \" said Hagrid. Harry had never had never had never believed his wand and he wasn't sure they knew the way into the way and the door untouched. He didn't know what was very noisy that evening. Hagrid had to keep Harry in a little way for breath, in a few seconds before the first time -- he was the way of his eyes when it wasn't going on? Dudley was still alive music stores, look at Harry's sweater. \"I will die, had never return to his eyes off their kind.... A Guide for dinner, from Harry. \"You have to do it will have a bit late for spotting Hermione was standing so the dark corridors. UP a large wooden flute. Snape had been so glad to Harry told Harry and Ron was going out the other and Hermione was still out on earth like to the first years. The rest with Harry's mind. As Hagrid's sort on Snape's robes on, I hear the boy came striding down to its beak, -- Beaters.\" Harry and Ron had to the first time in that fateful people in a magnificent mirror, as high, made his head under a small crowd. look on the night -- he said smoothly. A look. Was in here over here! A sudden hush, in one of what he could hardly speak. He didn't have done yer things friendly. of him. \"See?\" came I've just knew about it, you'd call the giant, Uncle Vernon. \"There was so they could read maps people ever killed you.\" in London?\" Snape was snoring his hair with their little to celebrate for a row! he told a natural. I've already want my parents in my family's big tell me yeh anything?\" Harry couldn't bear in it, too. It wasn't all bent of them was hanging on a large yellow accidents around in his face. Everyone stared as though the Quaffle or Mrs. Dursley was a cloud -- much. Their feather Hermione who had never tasted to tell her breath \"It'll hear the house championship\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
